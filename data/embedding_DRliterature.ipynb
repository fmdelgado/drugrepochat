{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1eb4334-d9ff-4d3c-9ba2-3609ae37c30c",
   "metadata": {},
   "source": [
    "# Embedding a whole set of pdfs in an automatic way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cdcc31d-39e3-4e5e-88e7-5b3f09ec944d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fernando/opt/anaconda3/envs/drugrepochat/lib/python3.10/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "#import necessary packages\n",
    "import os\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import subprocess\n",
    "import openai\n",
    "openai.api_key = \"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\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai.api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9559431c-ede6-4e4d-a384-8b784d37179f",
   "metadata": {},
   "source": [
    "## Retrieving the original list of articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23b03a9e-3b16-4486-898c-d667b85aec18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read the XLSX file\n",
    "dataframes = pd.read_excel('WhitepaperD23_classification.xlsx', sheet_name=['reviews', 'dbs', 'dbs_urls', 'tools'])\n",
    "\n",
    "# Do further processing with the DataFrame\n",
    "# For example, print the first few rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2639974f-8f17-409c-ad34-9a49f6cd7a13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reviews\n",
      "dbs\n",
      "dbs_urls\n",
      "tools\n"
     ]
    }
   ],
   "source": [
    "file_list = os.listdir('all_papers/')\n",
    "# Create a dictionary to map file names to paths\n",
    "file_path_dict = {}\n",
    "for file_path in file_list:\n",
    "    file_name = file_path.split('/')[-1]\n",
    "    file_path_dict[file_name] = f\"all_papers/{file_path}\"\n",
    "    \n",
    "\n",
    "# Function to find the closest matching file name\n",
    "def get_closest_match(title):\n",
    "    closest_match = process.extractOne(title, file_path_dict.keys(), scorer=fuzz.ratio)\n",
    "    if closest_match[1] >= 50:  # Adjust the threshold as per your requirements\n",
    "        return file_path_dict[closest_match[0]]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "for page, df in dataframes.items():\n",
    "    print(page)\n",
    "    df['pdf_path'] = df['Title'].apply(get_closest_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26312880-3ced-4a42-8fa2-50621fb8ce99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reviews False    86\n",
      "Name: pdf_path, dtype: int64\n",
      "dbs False    66\n",
      "Name: pdf_path, dtype: int64\n",
      "dbs_urls False    66\n",
      "Name: pdf_path, dtype: int64\n",
      "tools False    229\n",
      "Name: pdf_path, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "### Retrieving missing pdfs\n",
    "for page, df in dataframes.items():\n",
    "    print(page, df['pdf_path'].isna().value_counts())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e798267-3214-4c6c-8483-68fb9a397b69",
   "metadata": {},
   "source": [
    "## Loading pdfs and adding metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f50e84f3-7a77-463a-b08a-7a71b1d0e4a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.loc[df.Title == 'Cancer driver drug interaction explorer', 'pdf_path'] = \"/Users/fernando/Documents/Research/ChatGPT_REPO4EU/data/d23_repo4eu/data/all_papers/Hartung et al. 2022 - Cancer driver drug interaction explorer.pdf\"\n",
    "df.loc[df.Title == 'Drug Repositioning and Target Finding Based on Clinical Evidence', 'pdf_path']  = \"/Users/fernando/Documents/Research/ChatGPT_REPO4EU/data/d23_repo4eu/data/all_papers/Kaneko and Nagashima 2020 - Drug Repositioning and Target Finding Based on Clinical Evidence.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61bce9eb-68ed-4368-8979-5621857f4ee5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Name</th>\n",
       "      <th>Year Published</th>\n",
       "      <th>DOI</th>\n",
       "      <th>Pubmed Citations</th>\n",
       "      <th>Method</th>\n",
       "      <th>Strategy</th>\n",
       "      <th>Usability</th>\n",
       "      <th>Input</th>\n",
       "      <th>Output</th>\n",
       "      <th>Task Relevance</th>\n",
       "      <th>PMID</th>\n",
       "      <th>Labels</th>\n",
       "      <th>Note</th>\n",
       "      <th>pdf_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A weighted bilinear neural collaborative filte...</td>\n",
       "      <td>Name</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>doi.org/10.1093/bib/bbab581</td>\n",
       "      <td>20.0</td>\n",
       "      <td>deep learning</td>\n",
       "      <td>pathway-based</td>\n",
       "      <td>Package</td>\n",
       "      <td>Dataset with drug–disease associations</td>\n",
       "      <td>Complex drug–disease associations</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35039838.0</td>\n",
       "      <td>M1: deep learning | S1: pathway-based | U: Pac...</td>\n",
       "      <td>5. Input:  Dataset with drug–disease associati...</td>\n",
       "      <td>all_papers/Meng et al. 2022 - A weighted bilin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A network-based drug repurposing method via no...</td>\n",
       "      <td>Name</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>doi.org/10.1093/bioinformatics/btab826</td>\n",
       "      <td>4.0</td>\n",
       "      <td>machine learning, network models</td>\n",
       "      <td>pathway-based</td>\n",
       "      <td>Code</td>\n",
       "      <td>A drug–disease association matrix, a   dru...</td>\n",
       "      <td>Prediction of drug-related candidate diseas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34875000.0</td>\n",
       "      <td>M1: machine learning | M2: network models | S1...</td>\n",
       "      <td>5. Input    A drug–disease association matrix...</td>\n",
       "      <td>all_papers/Sadeghi et al. 2022 - A network-bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Robust disease module mining via enumeration o...</td>\n",
       "      <td>Name</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>doi.org/10.1093/bioinformatics/btab876</td>\n",
       "      <td>3.0</td>\n",
       "      <td>network models</td>\n",
       "      <td>phenotype-based</td>\n",
       "      <td>Code</td>\n",
       "      <td>Arguments are:    [1] file providing the netwo...</td>\n",
       "      <td>file    [4] initial fraction    [5] reduction ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34984440.0</td>\n",
       "      <td>M2: network models | S3: phenotype-based | U: ...</td>\n",
       "      <td>5. Input   Arguments are:    [1] file providi...</td>\n",
       "      <td>all_papers/Bernett et al. 2022 - Robust diseas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Task-driven knowledge graph filtering improves...</td>\n",
       "      <td>Name</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>doi.org/10.1186/s12859-022-04608-y</td>\n",
       "      <td>2.0</td>\n",
       "      <td>network models</td>\n",
       "      <td>knowledge-based, pathway-based</td>\n",
       "      <td>Code</td>\n",
       "      <td>Biomedical knowledge graph</td>\n",
       "      <td>Filtered biomedical knowledge graph</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35246025.0</td>\n",
       "      <td>M2: network models | S1: knowledge-based | S1:...</td>\n",
       "      <td>Input: Biomedical knowledge graph Output: Filt...</td>\n",
       "      <td>all_papers/Ratajczak et al. 2022 - Task-driven...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Overcoming Sparseness of Biomedical Networks t...</td>\n",
       "      <td>Name</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>doi.org/10.1109/TCBB.2021.3059807</td>\n",
       "      <td>1.0</td>\n",
       "      <td>network models</td>\n",
       "      <td>knowledge-based</td>\n",
       "      <td>Code, Not available</td>\n",
       "      <td>network, drug information.</td>\n",
       "      <td>predicted drug-target. The method is based on ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33591920.0</td>\n",
       "      <td>M2: network models | S1: knowledge-based | U: ...</td>\n",
       "      <td>Input: network, drug information. Output: pred...</td>\n",
       "      <td>all_papers/Poleksic 2022 - Overcoming Sparsene...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  Name  Year Published  \\\n",
       "0  A weighted bilinear neural collaborative filte...  Name          2022.0   \n",
       "1  A network-based drug repurposing method via no...  Name          2022.0   \n",
       "2  Robust disease module mining via enumeration o...  Name          2022.0   \n",
       "3  Task-driven knowledge graph filtering improves...  Name          2022.0   \n",
       "4  Overcoming Sparseness of Biomedical Networks t...  Name          2022.0   \n",
       "\n",
       "                                      DOI  Pubmed Citations  \\\n",
       "0             doi.org/10.1093/bib/bbab581              20.0   \n",
       "1  doi.org/10.1093/bioinformatics/btab826               4.0   \n",
       "2  doi.org/10.1093/bioinformatics/btab876               3.0   \n",
       "3      doi.org/10.1186/s12859-022-04608-y               2.0   \n",
       "4       doi.org/10.1109/TCBB.2021.3059807               1.0   \n",
       "\n",
       "                             Method                        Strategy  \\\n",
       "0                     deep learning                   pathway-based   \n",
       "1  machine learning, network models                   pathway-based   \n",
       "2                    network models                 phenotype-based   \n",
       "3                    network models  knowledge-based, pathway-based   \n",
       "4                    network models                 knowledge-based   \n",
       "\n",
       "             Usability                                              Input  \\\n",
       "0              Package             Dataset with drug–disease associations   \n",
       "1                 Code      A drug–disease association matrix, a   dru...   \n",
       "2                 Code  Arguments are:    [1] file providing the netwo...   \n",
       "3                 Code                         Biomedical knowledge graph   \n",
       "4  Code, Not available                        network, drug information.    \n",
       "\n",
       "                                              Output Task Relevance  \\\n",
       "0                  Complex drug–disease associations            NaN   \n",
       "1     Prediction of drug-related candidate diseas...            NaN   \n",
       "2  file    [4] initial fraction    [5] reduction ...            NaN   \n",
       "3                Filtered biomedical knowledge graph            NaN   \n",
       "4  predicted drug-target. The method is based on ...            NaN   \n",
       "\n",
       "         PMID                                             Labels  \\\n",
       "0  35039838.0  M1: deep learning | S1: pathway-based | U: Pac...   \n",
       "1  34875000.0  M1: machine learning | M2: network models | S1...   \n",
       "2  34984440.0  M2: network models | S3: phenotype-based | U: ...   \n",
       "3  35246025.0  M2: network models | S1: knowledge-based | S1:...   \n",
       "4  33591920.0  M2: network models | S1: knowledge-based | U: ...   \n",
       "\n",
       "                                                Note  \\\n",
       "0  5. Input:  Dataset with drug–disease associati...   \n",
       "1   5. Input    A drug–disease association matrix...   \n",
       "2   5. Input   Arguments are:    [1] file providi...   \n",
       "3  Input: Biomedical knowledge graph Output: Filt...   \n",
       "4  Input: network, drug information. Output: pred...   \n",
       "\n",
       "                                            pdf_path  \n",
       "0  all_papers/Meng et al. 2022 - A weighted bilin...  \n",
       "1  all_papers/Sadeghi et al. 2022 - A network-bas...  \n",
       "2  all_papers/Bernett et al. 2022 - Robust diseas...  \n",
       "3  all_papers/Ratajczak et al. 2022 - Task-driven...  \n",
       "4  all_papers/Poleksic 2022 - Overcoming Sparsene...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6f54199-6a81-4940-8aac-439aed9d144d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b99e6e3b-f4d5-402b-8a28-72da83e422ad",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "220it [02:13,  1.15it/s]Multiple definitions in dictionary at byte 0x26cf2 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x2713f for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x272fd for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x2753e for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x276b7 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x278e8 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x27a6e for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x27c84 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x27e6d for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x280a6 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x2832f for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x285c0 for key /MediaBox\n",
      "229it [02:17,  1.67it/s]\n"
     ]
    }
   ],
   "source": [
    "list_of_documents = []\n",
    "\n",
    "for index, row in tqdm(df.iterrows()):\n",
    "    if \"data\" not in row['pdf_path']:\n",
    "        filepath = \"/Users/fernando/Documents/Research/ChatGPT_REPO4EU/data/d23_repo4eu/data/\" + row['pdf_path']\n",
    "    else:\n",
    "        filepath = row['pdf_path']\n",
    "    \n",
    "    try:\n",
    "        loader = PyPDFLoader(filepath)\n",
    "        document = loader.load_and_split()\n",
    "        \n",
    "        for i in range(len(document)):\n",
    "            document[i].page_content = document[i].page_content.split(\"\\nReferences\\n\")[0]\n",
    "            document[i].metadata.update(row.to_dict())\n",
    "        list_of_documents.extend(document)\n",
    "    except:\n",
    "        print(f\"article not found!\\n{row['Title']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b51af9c-5942-4fb1-bef0-eca8bb3de1bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Embedding and vector-storing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc71a3bc-e87c-47d1-ae03-d96b57737cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sublist_docs = list_of_documents[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba84b625-7f72-48fa-8e4b-57de6b1a8fdf",
   "metadata": {},
   "source": [
    "#### FAISS implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4472000b-4704-4909-b7a4-0d14d5200db0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-dSjGt68lx8wYaJsN1IRLKdid on tokens per min. Limit: 1000000 / min. Current: 521974 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-dSjGt68lx8wYaJsN1IRLKdid on tokens per min. Limit: 1000000 / min. Current: 407601 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-dSjGt68lx8wYaJsN1IRLKdid on tokens per min. Limit: 1000000 / min. Current: 303688 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-dSjGt68lx8wYaJsN1IRLKdid on tokens per min. Limit: 1000000 / min. Current: 733383 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-dSjGt68lx8wYaJsN1IRLKdid on tokens per min. Limit: 1000000 / min. Current: 624322 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-dSjGt68lx8wYaJsN1IRLKdid on tokens per min. Limit: 1000000 / min. Current: 512997 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-dSjGt68lx8wYaJsN1IRLKdid on tokens per min. Limit: 1000000 / min. Current: 415281 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-dSjGt68lx8wYaJsN1IRLKdid on tokens per min. Limit: 1000000 / min. Current: 761717 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-dSjGt68lx8wYaJsN1IRLKdid on tokens per min. Limit: 1000000 / min. Current: 651609 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-dSjGt68lx8wYaJsN1IRLKdid on tokens per min. Limit: 1000000 / min. Current: 550994 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-dSjGt68lx8wYaJsN1IRLKdid on tokens per min. Limit: 1000000 / min. Current: 448822 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-dSjGt68lx8wYaJsN1IRLKdid on tokens per min. Limit: 1000000 / min. Current: 785816 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "my_embedding_model = OpenAIEmbeddings()\n",
    "\n",
    "vectordb = FAISS.from_documents(\n",
    "    documents=list_of_documents,\n",
    "    embedding=my_embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2bd6d144-aaac-4d07-b009-17ee00241c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import pickle\n",
    "\n",
    "def write_file(filename, content):\n",
    "    with open(filename, 'wb') as file:\n",
    "        file.write(content)\n",
    "\n",
    "\n",
    "def read_file(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "        return file.read()\n",
    "\n",
    "def store_index_in_db(index, name):\n",
    "    faiss.write_index(index.index, \"docs.index\")\n",
    "    # Open the file and dump to local storage\n",
    "    write_file(f\"{name}.index\", read_file(\"docs.index\"))\n",
    "    index.index = None\n",
    "    write_file(f\"{name}.pkl\", pickle.dumps(index))\n",
    "\n",
    "\n",
    "def load_index_from_db(index_name):\n",
    "    findex = read_file(f\"{index_name}.index\")\n",
    "\n",
    "    write_file(\"docs.index\", findex)\n",
    "    index = faiss.read_index(\"docs.index\")\n",
    "    VectorDB = pickle.loads(read_file(f\"{index_name}.pkl\"))\n",
    "    VectorDB.index = index\n",
    "\n",
    "    return VectorDB\n",
    "\n",
    "\n",
    "store_index_in_db(vectordb, \"repo4euD21\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18219c9a-703d-42e3-ad6c-f6bd2bd4d9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = load_index_from_db(\"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b3c6bda-91e3-47b2-b380-73278f4c5127",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4372\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(len(list_of_documents))\n",
    "print(len(index.docstore._dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44aa726c-edc5-450f-ac7d-ef48b156399c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Similarity searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "150eca19-3fc7-434a-bd5e-17ee724c3a7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='novo drug discovery has three steps: discovery stage,\\npreclinical stage and clinical stage [ 2], which usually\\nspans >10 years [ 3]. A recent study estimated that it\\ncosts $2.6 billion on average to develop a new drug\\napproved by the Food and Drug Administration in 2015,\\nas compared with $802 million in 2003 [ 4]. Biological\\nexperimental approaches pose considerable difficulties\\n(e.g. time-consuming, costly and high-risk). Hence,\\nrepurposing of ‘old’ drugs to treat both common and\\nrare diseases is becoming more and more attractive\\nbecause it involves the use of de-risked compounds,with potentially lower overall development costs and\\nshorter development timelines [\\n5–7]. Computational\\ndrug repurposing narrows down the search space fordrug–disease interactions by suggesting drug candidatesfor wet-lab validation [\\n8]. There is a pressing need,\\ntherefore, for novel computational drug repurposing\\nmethodologies to facilitate drug discovery.\\nThe drug repositioning problem can be modeled\\ncomputationally as a recommendation system that rec-\\nommends new indications based on known drug–disease\\nassociations. As the most typical drug repositioningmethod, matrix factorization projects drugs and diseases\\ninto a shared latent space, using a vector of latent\\nfeatures to represent a drug or a disease, and thereafterthe drug–disease association is modeled as the inner\\nproduct of their latent vectors. Matrix factorization and\\ncompletion algorithms have been widely and success-\\nfully used in bioinformatics research, such as uncovering\\nlncRNA–disease associations [\\n9], predicting microRNA–\\ndisease associations [ 10–12], discovering potential anti-\\nCOVID-19 drugs [ 13,14], identifying drug–drug interac-\\ntion prediction [ 15], predicting drug side effects [ 16] and\\nhandling the dropouts problem by modeling single-cellDownloaded from https://academic.oup.com/bib/article/23/2/bbab581/6510159 by Technische Universitaet Muenchen user on 01 December 2022', metadata={'source': '/Users/fernando/Documents/Research/ChatGPT_REPO4EU/data/d23_repo4eu/data/all_papers/Meng et al. 2022 - A weighted bilinear neural collaborative filtering approach for drug repositioning.pdf', 'page': 0, 'Title': 'A weighted bilinear neural collaborative filtering approach for drug repositioning', 'Name': 'Name', 'Year Published': 2022.0, 'DOI': 'doi.org/10.1093/bib/bbab581', 'Pubmed Citations': 20.0, 'Method': 'deep learning', 'Strategy': 'pathway-based', 'Usability': 'Package', 'Input': 'Dataset with drug–disease associations', 'Output': 'Complex drug–disease associations', 'Task Relevance': nan, 'PMID': 35039838.0, 'Labels': 'M1: deep learning | S1: pathway-based | U: Package |', 'Note': '5. Input:  Dataset with drug–disease associations    6. Output:  Complex drug–disease associations       7.\\xa0  One sentence summary:    A novel neighborhood and neighborhood interaction-based neural collaborative filtering approach (called DRWBNCF) to infer novel potential drugs for diseases', 'pdf_path': 'all_papers/Meng et al. 2022 - A weighted bilinear neural collaborative filtering approach for drug repositioning.pdf'}),\n",
       " Document(page_content='Yajie Meng is a doctoral student at Hunan University. Her research interests include bioinformatics and data mining.\\nChangcheng Lu is a graduate student at Hunan University. His research interests include bioinformatics and deep learning.\\nMin Jin is a professor at Hunan University. Her research interests include bioinformatics, artificial intelligence and data mining.\\nJunlin Xu is a doctoral student at Hunan University. His research interests include clustering, single cell, bioinformatics and computational biology.\\nXiangxiang Zeng is a professor at Hunan University. His research interests include bio-computing and bioinformatics.\\nJialiang Yang is the vice president of Geneis Beijing Co., Ltd. His research interests include bioinformatics, artificial intelligence and genomics.\\nReceived: October 13, 2021. Revised: November 25, 2021. Accepted: December 19, 2021\\n© The Author(s) 2022. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.comBriefings in Bioinformatics , 2022, 23(2), 1–13\\nhttps://doi.org/10.1093/bib/bbab581\\nProblem Solving Protocol\\nA weighted bilinear neural collaborative filtering\\napproach for drug repositioning\\nYajie Meng ,Changcheng Lu ,Min Jin ,Junlin Xu ,Xiangxiang Zeng and Jialiang Yang\\nCorresponding authors. Min Jin, College of Computer Science and Electronic Engineering, Hunan University, Changsha, Hunan, 410082, China.\\nE-mail: jinmin@hnu.edu.cn; Xiangxiang Zeng, College of Computer Science and Electronic Engineering, Hunan University, Changsha,Hunan, 410082, China. E-mail: xzeng@foxmail.com; Jialiang Yang, Geneis Beijing Co., Ltd, Beijing, 100102, China, E-mail: yangjl@geneis.cn\\nAbstract\\nDrug repositioning is an efficient and promising strategy for traditional drug discovery and development. Many research efforts are\\nfocused on utilizing deep-learning approaches based on a heterogeneous network for modeling complex drug–disease associations.Similar to traditional latent factor models, which directly factorize drug–disease associations, they assume the neighbors are\\nindependent of each other in the network and thus tend to be ineffective to capture localized information. In this study, we\\npropose a novel neighborhood and neighborhood interaction-based neural collaborative filtering approach (called DRWBNCF) to\\ninfer novel potential drugs for diseases. Specifically, we first construct three networks, including the known drug–disease association\\nnetwork, the drug–drug similarity and disease–disease similarity networks (using the nearest neighbors). To take the advantage oflocalized information in the three networks, we then design an integration component by proposing a new weighted bilinear graph\\nconvolution operation to integrate the information of the known drug–disease association, the drug’s and disease’s neighborhood\\nand neighborhood interactions into a unified representation. Lastly, we introduce a prediction component, which utilizes the multi-layer perceptron optimized by the α-balanced focal loss function and graph regularization to model the complex drug–disease\\nassociations. Benchmarking comparisons on three datasets verified the effectiveness of DRWBNCF for drug repositioning. Importantly,\\nthe unknown drug–disease associations predicted by DRWBNCF were validated against clinical trials and three authoritative databases\\nand we listed several new DRWBNCF-predicted potential drugs for breast cancer (e.g. valrubicin and teniposide) and small cell lung\\ncancer (e.g. valrubicin and cytarabine).\\nKeywords: drug, disease, drug–disease association prediction, drug repositioning, neighborhood interactions\\nIntroduction\\nDrugs are bioactive compounds that act on protein\\ntargets to cure/decelerate a specific disease or to\\npromote the health of a living being [ 1]. Traditional de\\nnovo drug discovery has three steps: discovery stage,\\npreclinical stage and clinical stage [ 2], which usually\\nspans >10 years [ 3]. A recent study estimated that it', metadata={'source': '/Users/fernando/Documents/Research/ChatGPT_REPO4EU/data/d23_repo4eu/data/all_papers/Meng et al. 2022 - A weighted bilinear neural collaborative filtering approach for drug repositioning.pdf', 'page': 0, 'Title': 'A weighted bilinear neural collaborative filtering approach for drug repositioning', 'Name': 'Name', 'Year Published': 2022.0, 'DOI': 'doi.org/10.1093/bib/bbab581', 'Pubmed Citations': 20.0, 'Method': 'deep learning', 'Strategy': 'pathway-based', 'Usability': 'Package', 'Input': 'Dataset with drug–disease associations', 'Output': 'Complex drug–disease associations', 'Task Relevance': nan, 'PMID': 35039838.0, 'Labels': 'M1: deep learning | S1: pathway-based | U: Package |', 'Note': '5. Input:  Dataset with drug–disease associations    6. Output:  Complex drug–disease associations       7.\\xa0  One sentence summary:    A novel neighborhood and neighborhood interaction-based neural collaborative filtering approach (called DRWBNCF) to infer novel potential drugs for diseases', 'pdf_path': 'all_papers/Meng et al. 2022 - A weighted bilinear neural collaborative filtering approach for drug repositioning.pdf'}),\n",
       " Document(page_content='2|Meng et al.\\nRNA-sequencing imputation [ 17]. Many studies have\\nsuggested that matrix factorization and completion\\nmethods become promising computational strategies\\nfor drug repositioning [ 18–21]. For instance, Luo et al.\\npresented a drug repositioning recommendation system\\n(called DRRS) based on the singular value thresholding\\n(SVT) algorithm to complete the large drug–diseaseadjacency matrix of a heterogeneous network, which\\nintegrated the disease–disease, drug–drug and drug–\\ndisease networks [\\n18]. Zhang et al. proposed a similarity\\nconstrained matrix factorization method called SCMFDD,\\nfor the drug–disease association prediction [ 22]. Different\\nfrom the conventional matrix factorization techniques,SCMFDD considers the biological context of the problem\\nby introducing drug–drug feature-based similarity and\\ndisease–disease semantic similarity as constraints for\\ndrugs and diseases. In order to optimize the fusion\\nprocess of multiple drug–drug and disease–diseasesimilarities, Yang et al. developed a novel matrix fac-\\ntorization method for drug repositioning, called MSBMF.\\nMSBMF concatenates multiple similarity matrices ofdrug and disease and decomposes the drug–disease\\nassociation matrix into a drug-feature matrix and a\\ndisease-feature matrix, which are constrained by non-negative factorization. Zhang et al. designed a novel drug\\nrepositioning method by using Bayesian inductive matrix\\ncompletion, termed DRIMC [\\n23]. The aforementioned\\nmethods can be regarded as a linear multiplication of\\nlatent features. Although these methods have achieved\\nstrong performance, a deficiency is that they cannoteffectively capture the complex structure of drug–\\ndisease association data and efficiently handle the high-\\ncomplexity matrix operations on large-scale data.\\nTo tackle the problem, some pioneering studies devel-\\noped deep-learning-based models for drug repositioning,such as deepDR [\\n24], LAGCN [ 25] and PADME [ 26]. Exist-\\ning deep-learning techniques mainly constructed a het-\\nerogeneous network by using drug’s and disease’s sideinformation and exploited deep-learning technologies to\\nthe heterogeneous network to learn better representa-\\ntion of drugs and diseases, which enhances the learningof drug–disease associations, and finally improves the\\nprediction accuracy. Nevertheless, similar to the matrix\\nfactorization and completion algorithms, they generallyutilize the global structure of the heterogeneous net-\\nwork and assume that the neighbors are independent\\nof each other, i.e. considering all similar neighbors andignoring the possible interactions between them. In some\\ncases, the interactions between neighbor nodes could\\nstrengthen the target node’s characteristics in a network.\\nFor example, an intuition in a transaction network is\\nthat a customer who has close business relations withrich friends would have a higher chance to repay a loan.\\nModeling such interactions between neighbors highlights\\nthe common properties, which could be helpful for therepresentation of the target node in a network. How-\\never, existing deep-learning models may be ineffective tocapture the interactions between neighbors and thus\\nlower the drug repositioning quality.\\nIn this study, we proposed a novel drug repositioning\\napproach based on weighted bilinear neural collabo-rative filtering, called DRWBNCF. To take advantage of\\nlocalized topology information in different domains, we\\nfirst constructed three networks, i.e. the known drug–disease association network, the drug–drug similarity\\nnetwork and the disease–disease similarity network to\\ncharacterize nearest neighbors and their interactionsinformation. Note that we utilized the neighborhood\\neffects from most similar drugs and most diseases to\\ncreate drug–drug and disease–disease similarity net-works. In this way, our model only uses nearest neighbors\\ninstead of all similar neighbors, and thus gets more\\naccurate results by filtering out noisy information. Then,', metadata={'source': '/Users/fernando/Documents/Research/ChatGPT_REPO4EU/data/d23_repo4eu/data/all_papers/Meng et al. 2022 - A weighted bilinear neural collaborative filtering approach for drug repositioning.pdf', 'page': 1, 'Title': 'A weighted bilinear neural collaborative filtering approach for drug repositioning', 'Name': 'Name', 'Year Published': 2022.0, 'DOI': 'doi.org/10.1093/bib/bbab581', 'Pubmed Citations': 20.0, 'Method': 'deep learning', 'Strategy': 'pathway-based', 'Usability': 'Package', 'Input': 'Dataset with drug–disease associations', 'Output': 'Complex drug–disease associations', 'Task Relevance': nan, 'PMID': 35039838.0, 'Labels': 'M1: deep learning | S1: pathway-based | U: Package |', 'Note': '5. Input:  Dataset with drug–disease associations    6. Output:  Complex drug–disease associations       7.\\xa0  One sentence summary:    A novel neighborhood and neighborhood interaction-based neural collaborative filtering approach (called DRWBNCF) to infer novel potential drugs for diseases', 'pdf_path': 'all_papers/Meng et al. 2022 - A weighted bilinear neural collaborative filtering approach for drug repositioning.pdf'})]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"what is drug repurposing?\"\n",
    "docs = index.similarity_search(question, k=3)\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358e61a6-3f84-486d-b32f-e166e2af8538",
   "metadata": {},
   "source": [
    "## Question answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16d3f060-01f1-4c95-8409-a919ff808b4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error in faiss::Index *faiss::read_index(faiss::IOReader *, int) at /Users/runner/work/faiss-wheels/faiss-wheels/faiss/faiss/impl/index_read.cpp:528: Error: 'ret == (1)' failed: read error in faiss_index/index.faiss: 0 != 1 (Resource temporarily unavailable)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/6t/jky9cnrn65x9gfpghzmvfpqh0000gp/T/ipykernel_57895/974264500.py\u001B[0m in \u001B[0;36m?\u001B[0;34m()\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0menviron\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"OPENAI_API_KEY\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mopenai\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapi_key\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[0mmy_embedding_model\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mOpenAIEmbeddings\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 15\u001B[0;31m \u001B[0mvectordb2\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mFAISS\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload_local\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"faiss_index\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmy_embedding_model\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     16\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/drugrepochat/lib/python3.10/site-packages/langchain/vectorstores/faiss.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(cls, folder_path, embeddings, index_name, **kwargs)\u001B[0m\n\u001B[1;32m    652\u001B[0m         \"\"\"\n\u001B[1;32m    653\u001B[0m         \u001B[0mpath\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mPath\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfolder_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    654\u001B[0m         \u001B[0;31m# load index separately since it is not picklable\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    655\u001B[0m         \u001B[0mfaiss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdependable_faiss_import\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 656\u001B[0;31m         index = faiss.read_index(\n\u001B[0m\u001B[1;32m    657\u001B[0m             \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpath\u001B[0m \u001B[0;34m/\u001B[0m \u001B[0;34m\"{index_name}.faiss\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mindex_name\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mindex_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    658\u001B[0m         )\n\u001B[1;32m    659\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/drugrepochat/lib/python3.10/site-packages/faiss/swigfaiss.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(*args)\u001B[0m\n\u001B[1;32m   9923\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mread_index\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 9924\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0m_swigfaiss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_index\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m: Error in faiss::Index *faiss::read_index(faiss::IOReader *, int) at /Users/runner/work/faiss-wheels/faiss-wheels/faiss/faiss/impl/index_read.cpp:528: Error: 'ret == (1)' failed: read error in faiss_index/index.faiss: 0 != 1 (Resource temporarily unavailable)"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "import os \n",
    "import openai\n",
    "\n",
    "openai.api_key = \"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\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai.api_key\n",
    "\n",
    "\n",
    "my_embedding_model = OpenAIEmbeddings()\n",
    "vectordb2 = FAISS.load_local(\"faiss_index\", my_embedding_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "741b27d6-e757-41b8-8c61-65a18cd431fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "# Build prompt\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        HumanMessagePromptTemplate.from_template(\"\"\"You are great at answering questions about drug repurposing in a concise\\\n",
    "                                                    and easy to understand manner. \\\n",
    "                                                    When you don't know the answer to a question you admit that you don't know\\\n",
    "                                                    Here is a question:\\\n",
    "                                                    {user_prompt}\"\"\")  \n",
    "    ],\n",
    "    input_variables=[\"user_prompt\"])\n",
    "\n",
    "\n",
    "label_query = prompt.format_prompt(user_prompt=\"Who is Yajie Meng?\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "53fb4f43-1ab9-49e2-a10a-5e5a660f047b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new RetrievalQA chain...\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "Yajie Meng is a doctoral student at Hunan University. Her research interests include bioinformatics and data mining.\n",
      "\n",
      "\n",
      "Sources:\n",
      "doi.org/10.1093/bib/bbab581\n",
      "doi.org/10.1093/bib/bbab581\n",
      "doi.org/10.1093/bib/bbab581\n",
      "doi.org/10.1093/bib/bbab581\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create the chain to answer questions\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=ChatOpenAI(temperature = 0.0, model='gpt-3.5-turbo'),\n",
    "                                  chain_type=\"stuff\",\n",
    "                                  retriever=vectordb2.as_retriever(),\n",
    "                                  return_source_documents=True,\n",
    "                                  verbose=True)\n",
    "\n",
    "# Cite sources\n",
    "def process_llm_response(llm_response):\n",
    "    print(llm_response['result'])\n",
    "    print('\\n\\nSources:')\n",
    "    for source in llm_response[\"source_documents\"]:\n",
    "        print(source.metadata['DOI'])\n",
    "        \n",
    "# Question\n",
    "query = \"Who is Yajie Meng?\"\n",
    "llm_response = qa_chain(prompt.format_prompt(user_prompt=query).to_string())\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc1a547-067d-432f-ad75-b7208ba375fb",
   "metadata": {},
   "source": [
    "## Implementing a chatbot with memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2d544bb1-dca3-4310-970c-a71e9b15ff18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.0)\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e09127bf-98f2-40e9-a5d0-1ead01b34b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, my name is Fernando\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello Fernando! It's nice to meet you. How can I assist you today?\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.save_context({\"input\": \"Not much, just hanging\"}, \n",
    "                    {\"output\": \"Cool\"})\n",
    "\n",
    "\n",
    "conversation.predict(input=\"Hi, my name is Fernando\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d1b164b2-1358-42d1-aa76-10e2de5392cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Fernando\n",
      "AI: Hello Fernando! It's nice to meet you. How can I assist you today?\n",
      "Human: What is my name?\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is Fernando.'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53cff76-1923-4fda-a365-150c977f7cee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}