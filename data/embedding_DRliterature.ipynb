{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1eb4334-d9ff-4d3c-9ba2-3609ae37c30c",
   "metadata": {},
   "source": [
    "# Embedding a whole set of pdfs in an automatic way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cdcc31d-39e3-4e5e-88e7-5b3f09ec944d",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-08-04T17:28:36.910749Z",
     "start_time": "2023-08-04T17:28:36.910079Z"
    }
   },
   "outputs": [],
   "source": [
    "#import necessary packages\n",
    "import os\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import subprocess\n",
    "import openai\n",
    "openai.api_key = \"\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai.api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9559431c-ede6-4e4d-a384-8b784d37179f",
   "metadata": {},
   "source": [
    "## Retrieving the original list of articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23b03a9e-3b16-4486-898c-d667b85aec18",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-08-04T17:28:39.463794Z",
     "start_time": "2023-08-04T17:28:39.142091Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read the XLSX file\n",
    "dataframes = pd.read_excel('WhitepaperD23_classification.xlsx', sheet_name=['reviews', 'dbs', 'dbs_urls', 'tools'])\n",
    "\n",
    "# Do further processing with the DataFrame\n",
    "# For example, print the first few rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2639974f-8f17-409c-ad34-9a49f6cd7a13",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-08-04T17:30:05.822485Z",
     "start_time": "2023-08-04T17:28:42.697248Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reviews\n",
      "dbs\n",
      "dbs_urls\n",
      "tools\n"
     ]
    }
   ],
   "source": [
    "file_list = os.listdir('all_papers/')\n",
    "# Create a dictionary to map file names to paths\n",
    "file_path_dict = {}\n",
    "for file_path in file_list:\n",
    "    file_name = file_path.split('/')[-1]\n",
    "    file_path_dict[file_name] = f\"all_papers/{file_path}\"\n",
    "    \n",
    "\n",
    "# Function to find the closest matching file name\n",
    "def get_closest_match(title):\n",
    "    closest_match = process.extractOne(title, file_path_dict.keys(), scorer=fuzz.ratio)\n",
    "    if closest_match[1] >= 50:  # Adjust the threshold as per your requirements\n",
    "        return file_path_dict[closest_match[0]]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "for page, df in dataframes.items():\n",
    "    print(page)\n",
    "    df['pdf_path'] = df['Title'].apply(get_closest_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26312880-3ced-4a42-8fa2-50621fb8ce99",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-08-04T17:30:05.836923Z",
     "start_time": "2023-08-04T17:30:05.829708Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reviews False    86\n",
      "Name: pdf_path, dtype: int64\n",
      "dbs False    66\n",
      "Name: pdf_path, dtype: int64\n",
      "dbs_urls False    66\n",
      "Name: pdf_path, dtype: int64\n",
      "tools False    229\n",
      "Name: pdf_path, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "### Retrieving missing pdfs\n",
    "for page, df in dataframes.items():\n",
    "    print(page, df['pdf_path'].isna().value_counts())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e798267-3214-4c6c-8483-68fb9a397b69",
   "metadata": {},
   "source": [
    "## Loading pdfs and adding metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f50e84f3-7a77-463a-b08a-7a71b1d0e4a5",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-08-04T17:56:59.358581Z",
     "start_time": "2023-08-04T17:56:59.354180Z"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[df.Title == 'Cancer driver drug interaction explorer', 'pdf_path'] = \"/Users/fernando/Documents/Research/ChatGPT_REPO4EU/data/d23_repo4eu/data/all_papers/Hartung et al. 2022 - Cancer driver drug interaction explorer.pdf\"\n",
    "df.loc[df.Title == 'Drug Repositioning and Target Finding Based on Clinical Evidence', 'pdf_path']  = \"/Users/fernando/Documents/Research/ChatGPT_REPO4EU/data/d23_repo4eu/data/all_papers/Kaneko and Nagashima 2020 - Drug Repositioning and Target Finding Based on Clinical Evidence.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "61bce9eb-68ed-4368-8979-5621857f4ee5",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-08-04T17:57:00.918791Z",
     "start_time": "2023-08-04T17:57:00.915335Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6f54199-6a81-4940-8aac-439aed9d144d",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-08-04T17:32:08.797374Z",
     "start_time": "2023-08-04T17:32:08.788600Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b99e6e3b-f4d5-402b-8a28-72da83e422ad",
   "metadata": {
    "scrolled": true,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-08-04T17:34:33.121836Z",
     "start_time": "2023-08-04T17:32:09.969278Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "220it [02:19,  1.09it/s]Multiple definitions in dictionary at byte 0x26cf2 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x2713f for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x272fd for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x2753e for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x276b7 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x278e8 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x27a6e for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x27c84 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x27e6d for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x280a6 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x2832f for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x285c0 for key /MediaBox\n",
      "229it [02:23,  1.60it/s]\n"
     ]
    }
   ],
   "source": [
    "list_of_documents = []\n",
    "\n",
    "for index, row in tqdm(df.iterrows()):\n",
    "    if \"data\" not in row['pdf_path']:\n",
    "        filepath = \"/Users/fernando/Documents/Research/ChatGPT_REPO4EU/data/d23_repo4eu/data/\" + row['pdf_path']\n",
    "    else:\n",
    "        filepath = row['pdf_path']\n",
    "    \n",
    "    try:\n",
    "        loader = PyPDFLoader(filepath)\n",
    "        document = loader.load_and_split()\n",
    "        \n",
    "        for i in range(len(document)):\n",
    "            document[i].page_content = document[i].page_content.split(\"\\nReferences\\n\")[0]\n",
    "            document[i].metadata.update(row.to_dict())\n",
    "        list_of_documents.extend(document)\n",
    "    except:\n",
    "        print(f\"article not found!\\n{row['Title']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b51af9c-5942-4fb1-bef0-eca8bb3de1bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Embedding and vector-storing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc71a3bc-e87c-47d1-ae03-d96b57737cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sublist_docs = list_of_documents[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba84b625-7f72-48fa-8e4b-57de6b1a8fdf",
   "metadata": {},
   "source": [
    "#### FAISS implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4472000b-4704-4909-b7a4-0d14d5200db0",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-08-04T17:31:21.294804Z",
     "start_time": "2023-08-04T17:31:19.888398Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "my_embedding_model = OpenAIEmbeddings()\n",
    "\n",
    "vectordb = FAISS.from_documents(\n",
    "    documents=list_of_documents,\n",
    "    embedding=my_embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bd6d144-aaac-4d07-b009-17ee00241c85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-04T17:30:59.857280Z",
     "start_time": "2023-08-04T17:30:59.742598Z"
    }
   },
   "outputs": [],
   "source": [
    "import faiss\n",
    "import pickle\n",
    "\n",
    "def write_file(filename, content):\n",
    "    with open(filename, 'wb') as file:\n",
    "        file.write(content)\n",
    "\n",
    "\n",
    "def read_file(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "        return file.read()\n",
    "\n",
    "def store_index_in_db(index, name):\n",
    "    faiss.write_index(index.index, \"docs.index\")\n",
    "    # Open the file and dump to local storage\n",
    "    write_file(f\"{name}.index\", read_file(\"docs.index\"))\n",
    "    index.index = None\n",
    "    write_file(f\"{name}.pkl\", pickle.dumps(index))\n",
    "\n",
    "\n",
    "def load_index_from_db(index_name):\n",
    "    findex = read_file(f\"{index_name}.index\")\n",
    "\n",
    "    write_file(\"docs.index\", findex)\n",
    "    index = faiss.read_index(\"docs.index\")\n",
    "    VectorDB = pickle.loads(read_file(f\"{index_name}.pkl\"))\n",
    "    VectorDB.index = index\n",
    "\n",
    "    return VectorDB\n",
    "\n",
    "\n",
    "store_index_in_db(vectordb, \"repo4euD21\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18219c9a-703d-42e3-ad6c-f6bd2bd4d9e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-04T17:37:18.369071Z",
     "start_time": "2023-08-04T17:37:18.165255Z"
    }
   },
   "outputs": [],
   "source": [
    "index = load_index_from_db(\"repo4euD21\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b3c6bda-91e3-47b2-b380-73278f4c5127",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-08-04T17:37:19.248862Z",
     "start_time": "2023-08-04T17:37:19.245961Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4372\n",
      "4372\n"
     ]
    }
   ],
   "source": [
    "print(len(list_of_documents))\n",
    "print(len(index.docstore._dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44aa726c-edc5-450f-ac7d-ef48b156399c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Similarity searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "150eca19-3fc7-434a-bd5e-17ee724c3a7f",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-07-31T08:43:08.335726Z",
     "start_time": "2023-07-31T08:43:08.091899Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[Document(page_content='3 \\n 1. Introduction  1 \\nDrug repurposing (DR) is the process of identifying new therapeutic applications for existing drugs 2 \\n[1]. Over the past few years, pharmaceutical industries have hugely invested in the repositioning  of 3 \\napproved  and withdrawn  drugs  as traditional  drug development  is an extremely  expensive, 4 \\nlaborious, time -consuming, and highly failure -prone avenue  [2-6]. DR especially finds its 5 \\napplication in rare and  neglected diseases where there are very few or no drugs available for 6 \\ntreatment  [7]. The US -FDA has provided a list of approved pharmaceuticals that can be promising 7 \\ndrug candidates for  repurposing in rare disea ses [8]. Nonetheless, it has always been an endeavour  to 8 \\nidentify drugs  that are equipotent  to such orphan  drugs.  DR also finds  its application  in 9 \\ninfectious  diseases such  as tuberculosis [ 9-15], HIV and other communicable diseases where multi - 10 \\ndrug resistance is a  major  problem  [16-18]. Currently,  DR is also used to identify  promising  drugs  11 \\nfor non-communicable diseases  like cancer  [19], neurological  [20], inflammatory bowel disease  [21] 12 \\nand cardi ovascular diseases  [22-23]. For this purpose, both experimental and computational DR 13 \\napproaches have been used to identify potential  candidates for several diseases  [24]. Experimental 14 \\ndrug repurposing approaches majorly include proteomics techniques  [25-26] and in vitro  high 15 \\nthroughput screenings  [27] whereas chemoinformatics, data -driven and statistical methods involving 16 \\ngene -target -disease level associations and structural analysis of existing drugs are the computational 17 \\napproaches  [28-32]. Also, the adva ncement in computational drug discovery processes has proved 18 \\nhelpful in identifying potential lead molecules in various studies  [33-42]. Moreover, the availability  19 \\nof enormous  data related to the physicochemical and pharmacological properties of existing  drugs 20 \\nand clinical trial information of prospective drug molecules has further aided in  identifying  21 \\npromising  candidates  for DR [43-46]. Hence the 21st century pharmaceutical science is largely 22 \\ndependent on the synergistic use of data -driven and experiment al approaches to drug repositioning.  23 \\nOver the past few  decades, several dozens drugs have been repurposed successfully for many new 24 \\nindications outside the scope of their native therapeutic application using experimental, in silico  and 25 \\ndata driven approac hes [47]. It is therefore imperative to instil newer data analytical methods to 26 \\nmake a substantial effort in designing effective therapeutics. Statistical and data driven approaches 27 \\nare mostly dependent on the structure of drug molecules  [48]. There are ma ny freely available drug 28 \\ndatabases like DrugBank  [49], DrugCental  [50], PubChem  [51], Therapeutic Target Database (TTD)  29 \\n[52], CenterWatch  [53], United States Food and Drug Administration (US -FDA)  [54] which 30 \\nprovides physicochemical and pharmacological profiles of approved drugs across all the major 31 \\nregulatory bodies like FDA, Health Canada, EMA, etc.  32 \\nSignificant efforts have been made to analyze  these drugs using statistical and machine learning 33 \\nappro aches based on the available enormous data  [55]. Consequently, descriptor  analysis  of 34 \\nJournal Pre-proof', metadata={'source': '/Users/fernando/Documents/Research/ChatGPT_REPO4EU/data/d23_repo4eu/data/all_papers/Madugula et al. 2021 - Molecular descriptor analysis of approved drugs using unsupervised learning for drug repurposing.pdf', 'page': 4, 'Title': 'Molecular descriptor analysis of approved drugs using unsupervised learning for drug repurposing', 'Name': 'Name', 'Year Published': 2021.0, 'DOI': 'doi.org/10.1016/j.compbiomed.2021.104856', 'Pubmed Citations': 1.0, 'Method': 'machine learning', 'Strategy': 'mechanism-based, target-based', 'Usability': 'Not available', 'Input': 'Molecular structure classification (descriptor), drug-target data, target-disease data ', 'Output': 'List of potential drug repurposing candidates and associated disease', 'Task Relevance': nan, 'PMID': 34555571.0, 'Labels': 'M1: machine learning | S1: mechanism-based | S1: target-based | U: Not available |', 'Note': 'Input: Molecular structure classification (descriptor), drug-target data, target-disease data Output: List of potential drug repurposing candidates and associated disease  Summary: After employing a molecular descriptor analysis on the chemical structure of drugs, their potential to be repurposed for other indications is scored via unsupervised learning (PCA, k-means clustering). ', 'pdf_path': 'all_papers/Madugula et al. 2021 - Molecular descriptor analysis of approved drugs using unsupervised learning for drug repurposing.pdf'}),\n Document(page_content='INTRODUCTION\\nDrug repurposing, or repositioning,1is the quest to identify new\\nuses for existing drugs. It holds great promise for both patients andindustry, as it significantly reduces the costs and time-to-market ofnew medications compared to de novo drug discovery.\\n2To date, the\\nmost notable repurposed drugs have been discovered either throughserendipity, based on specific pharmacological insights, or using ex-perimental screening platforms.\\n2,3To accelerate and increase the\\nscale of such discoveries, numerous computational methods havebeen suggested to aid in drug repurposing (see reviews in refs\\n3–8).\\nFor example, a popular approach, which can be applied to different\\ndata types, represents drugs and/or diseases as feature vectors (aka“signatures” or “profiles”), and measures the similarity betweenthese entities or trains a prediction model for drug–diseaseassociations.\\nIn the healthcare domain, the term “real-world data” refers to\\ninformation collected outside the clinical research settings; for ex-ample, in electronic health records (EHRs) or claims and billingdata.\\n9Such data offer important advantages in terms of volume and\\ntimeline span, alongside some inherent challenges such as data irreg-ularity and incompleteness. Recently, real-world data have been in-creasingly leveraged for various healthcare applications.\\n10In the\\ncontext of drug repurposing, observational data are increasinglyused to provide external validation to existing drug repurposing hy-potheses. For example, Xu et al\\n11used EHR data to validate the as-\\nsociation of metformin with reduced cancer mortality. In contrast,there are far fewer examples for utilizing observational data to gen-\\nerate new drug repurposing hypotheses. Paik et al\\n12derived drug\\nand disease similarities from EHR data and then combined thesesimilarities to score drug–disease pairs and suggest novel drug repur-posing hypotheses. Kuang et al\\n13leveraged patient-level longitudinal\\ninformation available in EHRs and applied the Self-Controlled CaseSeries study design, widely used to identify adverse drug reactions,\\n14\\nto suggest new drugs that can control fasting blood glucose levels.Wu et al\\n15employed a multivariable Cox regression model to assess\\nthe effect of 146 noncancer drugs on cancer survival in EHR data.Suchard et al\\n16utilized EHR and claims databases to estimate the ef-\\nficacy and safety profile of multiple first-line drug classes for hyper-tension treatment. They calculated the hazard ratios of thecompared classes with Cox models, after stratifying or matchingpatients by propensity score.\\nConducting a randomized controlled trial (RCT), the gold stan-\\ndard for validating the efficacy of a candidate drug, is costly andlengthy. To identify promising repurposing candidates, we proposea framework that emulates RCTs for on-market drugs using obser-\\nvational real-world data. We apply causal inference methodologiesto correct for confounding bias in treatment assignment, treatmentduration, and informative censoring.\\n17Our framework is configura-\\nble, allowing for the specification of inclusion criteria, disease out-come, and potential confounders.\\nAs a test case, we applied the described drug repurposing frame-\\nwork to Parkinson’s disease (PD). To date, all drugs indicated forPD are approved for treating its symptoms and none was shown toslow the progression of the disease.\\n18We emulated RCTs for hun-\\ndreds of drugs, including PD indicated drugs, estimating their effecton three disease progression outcomes. To assess the robustness ofour framework, we tested the agreement of the estimated effectsacross different causal inference methods and databases. We focushere on the methodological aspects of our framework and the meansto validate its results. A discussion of the identified drug candidatesfor PD and their clinical validity appears in Laifenfeld et al.\\n19To the', metadata={'source': 'all_papers/Ozery-Flato et al. 2020 - Framework for identifying drug repurposing candidates from observational healthcare data.pdf', 'page': 1, 'Title': 'Framework for identifying drug repurposing candidates from observational healthcare data', 'Name': 'Name', 'Year Published': 2020.0, 'DOI': 'doi.org/10.1093/jamiaopen/ooaa048', 'Pubmed Citations': 9.0, 'Method': 'machine learning', 'Strategy': 'phenotype-based', 'Usability': 'Not available', 'Input': 'Observational healthcare data', 'Output': 'Predicted new drug indications', 'Task Relevance': '2.4', 'PMID': 33623890.0, 'Labels': 'M1: machine learning | S3: phenotype-based | T2.4: Indication Drug | U: Not available |', 'Note': 'Input: Observational healthcare data Output: Predicted new drug indications  Summary: The authors present a framework for finding drug repurposing candidates by emulating randomized controlled trials (RTC) using medical databases and causal inference methodology.\\xa0', 'pdf_path': 'all_papers/Ozery-Flato et al. 2020 - Framework for identifying drug repurposing candidates from observational healthcare data.pdf'}),\n Document(page_content='passing from preclinical development to Phase I clinical \\nstudies [ 7], alternative strategies are needed. Drug repur -\\nposing is an attractive strategy to identify novel treat -\\nment options given that it may reduce R&D timelines by \\n3–5\\xa0years, have less development costs and the improved \\nquality of success [ 8, 9]. The concept of drug repurpos -\\ning is not new and many new drug indications have been \\nidentified serendipitously. The classic cases include Silde -\\nnafil that was initially approved for angina but repur -\\nposed for erectile dysfunction and Canakinumab which Open Access\\n*Correspondence:  davidjwild@indiana.edu; anshu@imtech.res.in\\n2 Academy of  Scientific and  Innovative Research, Council of  Scientific \\nand Industrial Research, Training and Development Complex, CSIR \\nCampus, CSIR Road, Taramani, Chennai, Tamil Nadu 600113, India\\n3 School of  Informatics, Computing, and  Engineering, Indiana University, \\nBloomington, IN 47405, USA\\nFull list of author information is available at the end of the article', metadata={'source': '/Users/fernando/Documents/Research/ChatGPT_REPO4EU/data/d23_repo4eu/data/all_papers/Passi et al. 2018 - RepTB - a gene ontology based drug repurposing approach for tuberculosis.pdf', 'page': 0, 'Title': 'RepTB: a gene ontology based drug repurposing approach for tuberculosis', 'Name': 'Name', 'Year Published': 2018.0, 'DOI': 'doi.org/10.1186/s13321-018-0276-9', 'Pubmed Citations': 4.0, 'Method': 'network models, comp. val.', 'Strategy': 'knowledge-based', 'Usability': 'Code', 'Input': 'Drug-target interactions (DrugBank), GO mapping information (QuickGO), chemical structure similarity between known and predicted drugs for prioritized targets', 'Output': 'List of predicted drug-target interactions that may have a synergistic bactericidal effect against TB and may be suitable for further validation as potential starting points in the TB drug discovery pipeline.', 'Task Relevance': '2.4, 2.6, 2.8', 'PMID': 29785561.0, 'Labels': 'M2: network models | M4: comp. val. | S1: knowledge-based | T2.4: Indication Drug | T2.6: Drugs Complex Diseases | T2.8: Comp. Validation | U: Code |', 'Note': 'input:\\xa0Data about known drug-target interactions, which is obtained from the DrugBank database., , Gene Ontology (GO) mapping information, which is downloaded from the QuickGO database of the European Bioinformatics Institute (EBI). This information is used to enrich the network with molecular function ontology., , The Gene Ontology-based network, which is constructed based on the known drug-target interactions and the GO mapping information., , Parameters for the Network Based Inference (NBI) analysis, which is used to compute association scores for the identification of new drug-target interactions., , Evidence-based criteria for evaluating the potential of predicted drug-target interactions as drug repurposing candidates for TB., , Information about the chemical structure similarity between known and predicted drugs for prioritized targets, which is used to assess the chemical diversity of the predicted drug-target interactions.   output: list of predicted drug-target interactions that may have a synergistic bactericidal effect against TB and may be suitable for further validation as potential starting points in the TB drug discovery pipeline.   1sentsum:\\xa0\\xa0drug repurposing method for tuberculosis (TB) that aims to identify novel drug-target interactions for the treatment of TB. The method uses a Gene Ontology-based network, which contains information about known drug-target pairs and their molecular functions, to predict novel drug-target interactions. The association scores computed from this network are then used to identify potential drug repurposing candidates for TB.\\xa0  ', 'pdf_path': 'all_papers/Passi et al. 2018 - RepTB - a gene ontology based drug repurposing approach for tuberculosis.pdf'})]"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"what is drug repurposing?\"\n",
    "docs = index.similarity_search(question, k=3)\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358e61a6-3f84-486d-b32f-e166e2af8538",
   "metadata": {},
   "source": [
    "## Question answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "16d3f060-01f1-4c95-8409-a919ff808b4c",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-07-31T08:44:49.298041Z",
     "start_time": "2023-07-31T08:44:49.288595Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error in faiss::FileIOReader::FileIOReader(const char *) at /Users/runner/work/faiss-wheels/faiss-wheels/faiss/faiss/impl/io.cpp:68: Error: 'f' failed: could not open repo4euD21.index/index.faiss for reading: Not a directory",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/6t/jky9cnrn65x9gfpghzmvfpqh0000gp/T/ipykernel_3217/2810735980.py\u001B[0m in \u001B[0;36m?\u001B[0;34m()\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0menviron\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"OPENAI_API_KEY\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mopenai\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapi_key\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[0mmy_embedding_model\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mOpenAIEmbeddings\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 14\u001B[0;31m \u001B[0mvectordb2\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mFAISS\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload_local\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"repo4euD21.index\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmy_embedding_model\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     15\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/drugrepochat/lib/python3.10/site-packages/langchain/vectorstores/faiss.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(cls, folder_path, embeddings, index_name, **kwargs)\u001B[0m\n\u001B[1;32m    652\u001B[0m         \"\"\"\n\u001B[1;32m    653\u001B[0m         \u001B[0mpath\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mPath\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfolder_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    654\u001B[0m         \u001B[0;31m# load index separately since it is not picklable\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    655\u001B[0m         \u001B[0mfaiss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdependable_faiss_import\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 656\u001B[0;31m         index = faiss.read_index(\n\u001B[0m\u001B[1;32m    657\u001B[0m             \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpath\u001B[0m \u001B[0;34m/\u001B[0m \u001B[0;34m\"{index_name}.faiss\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mindex_name\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mindex_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    658\u001B[0m         )\n\u001B[1;32m    659\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/drugrepochat/lib/python3.10/site-packages/faiss/swigfaiss.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(*args)\u001B[0m\n\u001B[1;32m   9923\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mread_index\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 9924\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0m_swigfaiss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_index\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m: Error in faiss::FileIOReader::FileIOReader(const char *) at /Users/runner/work/faiss-wheels/faiss-wheels/faiss/faiss/impl/io.cpp:68: Error: 'f' failed: could not open repo4euD21.index/index.faiss for reading: Not a directory"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "import os \n",
    "import openai\n",
    "\n",
    "openai.api_key = \"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\"\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai.api_key\n",
    "\n",
    "\n",
    "my_embedding_model = OpenAIEmbeddings()\n",
    "vectordb2 = FAISS.load_local(\"repo4euD21.index\", my_embedding_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "741b27d6-e757-41b8-8c61-65a18cd431fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T08:43:26.145652Z",
     "start_time": "2023-07-31T08:43:26.142165Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "# Build prompt\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        HumanMessagePromptTemplate.from_template(\"\"\"You are great at answering questions about drug repurposing in a concise\\\n",
    "                                                    and easy to understand manner. \\\n",
    "                                                    When you don't know the answer to a question you admit that you don't know\\\n",
    "                                                    Here is a question:\\\n",
    "                                                    {user_prompt}\"\"\")  \n",
    "    ],\n",
    "    input_variables=[\"user_prompt\"])\n",
    "\n",
    "\n",
    "label_query = prompt.format_prompt(user_prompt=\"Who is Yajie Meng?\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "53fb4f43-1ab9-49e2-a10a-5e5a660f047b",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-07-31T08:43:29.177671Z",
     "start_time": "2023-07-31T08:43:29.159286Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectordb2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[50], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Create the chain to answer questions\u001B[39;00m\n\u001B[1;32m      2\u001B[0m qa_chain \u001B[38;5;241m=\u001B[39m RetrievalQA\u001B[38;5;241m.\u001B[39mfrom_chain_type(llm\u001B[38;5;241m=\u001B[39mChatOpenAI(temperature \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m, model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgpt-3.5-turbo\u001B[39m\u001B[38;5;124m'\u001B[39m),\n\u001B[1;32m      3\u001B[0m                                   chain_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstuff\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m----> 4\u001B[0m                                   retriever\u001B[38;5;241m=\u001B[39m\u001B[43mvectordb2\u001B[49m\u001B[38;5;241m.\u001B[39mas_retriever(),\n\u001B[1;32m      5\u001B[0m                                   return_source_documents\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m      6\u001B[0m                                   verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# Cite sources\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mprocess_llm_response\u001B[39m(llm_response):\n",
      "\u001B[0;31mNameError\u001B[0m: name 'vectordb2' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create the chain to answer questions\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=ChatOpenAI(temperature = 0.0, model='gpt-3.5-turbo'),\n",
    "                                  chain_type=\"stuff\",\n",
    "                                  retriever=vectordb2.as_retriever(),\n",
    "                                  return_source_documents=True,\n",
    "                                  verbose=True)\n",
    "\n",
    "# Cite sources\n",
    "def process_llm_response(llm_response):\n",
    "    print(llm_response['result'])\n",
    "    print('\\n\\nSources:')\n",
    "    for source in llm_response[\"source_documents\"]:\n",
    "        print(source.metadata['DOI'])\n",
    "        \n",
    "# Question\n",
    "query = \"Who is Yajie Meng?\"\n",
    "llm_response = qa_chain(prompt.format_prompt(user_prompt=query).to_string())\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc1a547-067d-432f-ad75-b7208ba375fb",
   "metadata": {},
   "source": [
    "## Implementing a chatbot with memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2d544bb1-dca3-4310-970c-a71e9b15ff18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.0)\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e09127bf-98f2-40e9-a5d0-1ead01b34b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, my name is Fernando\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello Fernando! It's nice to meet you. How can I assist you today?\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.save_context({\"input\": \"Not much, just hanging\"}, \n",
    "                    {\"output\": \"Cool\"})\n",
    "\n",
    "\n",
    "conversation.predict(input=\"Hi, my name is Fernando\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d1b164b2-1358-42d1-aa76-10e2de5392cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Fernando\n",
      "AI: Hello Fernando! It's nice to meet you. How can I assist you today?\n",
      "Human: What is my name?\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is Fernando.'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53cff76-1923-4fda-a365-150c977f7cee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
